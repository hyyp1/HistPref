### Anonymous Repository for Personas Influence Deeply: Enhancing Interaction with Large Language Models via Inference-time Alignment

#### asserts:

All the figures and tables appeared in our paper.

#### code:

The source code of our paper, including data construction scripts, prompts, training scripts, etc.

#### data:

├── dataset

├── log

└── sample_real_data

* dataset: The main data of InterPref, including `history_map.jsonl`, which contains the interaction history corresponding to each preference; `sharegpt_pairs.json`, our confidential dataset containing real dialogues; `train_dataset.jsonl` and `test_dataset.jsonl`, which represent our training and test dataset splits.
* log: The running results of all models in our experiment.
